# Codebase Concatenation - 2025-03-21 08:04:13
Total files: 15



================================================================================
FILE: ./README.md
================================================================================

# Project Summary
> Last updated: 2025-03-21 08:01:00

# Codebase Summary

## Project Purpose and Main Functionality
The project implements a client-server system primarily designed for a Raspberry Pi equipped with various hardware components such as a RealSense camera, servo motors, and an audio detection system. The main functionality of the system is to capture and process video and audio data, control servo motors based on received commands, and communicate with a server via WebSockets. The system can operate in a real or simulated hardware environment.

## Key Components and Their Interactions
- **WebSocketClient**: Manages the WebSocket connection, handling the sending of telemetry, camera frames, and receiving commands from the server.
- **RealSenseCamera**: Interfaces with an Intel RealSense camera to capture color and depth frames.
- **ServoController**: Manages servo motors for physical movements based on received commands.
- **AudioDetector**: Processes audio signals to detect sound levels and directions.
- **MessageHandler**: Handles sending and receiving messages to/from the server, although detailed implementation is not provided.

These components interact mainly through the `WebSocketClient` class, which orchestrates the data flow between the server and the local hardware components. The client initializes the hardware components, connects to the server, and continuously processes and sends data (like camera frames and telemetry) while receiving and executing commands (like servo movements).

## Technologies and Libraries Used
- **Python 3**: Main programming language.
- **asyncio and websockets**: For asynchronous network programming and WebSocket communication.
- **OpenCV (cv2)**: For image processing tasks.
- **NumPy**: Used for numerical operations, especially in handling image data.
- **logging**: For logging information, warnings, and errors.
- **argparse**: For parsing command-line options.
- **RPi.GPIO, adafruit-blinka**: Libraries for interfacing with the GPIO pins on a Raspberry Pi for controlling hardware like servo motors.

## Notable Implementation Details
- The system can switch between real and simulation modes using a command-line argument, allowing development and testing without actual hardware.
- The client attempts to reconnect to the server with exponential backoff strategy in case of connection losses.
- Telemetry data includes system metrics such as CPU temperature, memory usage, and uptime, which are sent periodically to the server.
- The system is designed to be modular, where each hardware component (camera, servos, audio) is encapsulated in its class with specific responsibilities.

Overall, the system is structured to be robust and modular, facilitating easy maintenance and scalability. The use of asynchronous programming ensures that the system can handle real-time data processing and communication efficiently.

## Auto-generated Summary
This README was automatically generated by a script that concatenates the codebase
and uses OpenAI's API to generate a summary.



================================================================================
FILE: ./client/client.py
================================================================================

#!/usr/bin/env python3
import asyncio
import websockets
import logging
import json
import time
import base64
import cv2
import numpy as np
import socket
import sys
import argparse
import os
import traceback
from queue import Queue, Empty
import statistics
from typing import Dict, List, Optional, Any
import random

# Import hardware modules
from hardware.camera.realsense_camera import RealSenseCamera
from hardware.servo.controller import ServoController
from hardware.audio.audio_detector import AudioDetector

# Import config and utilities
import config

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("client_log.txt"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Parse command line arguments
parser = argparse.ArgumentParser(description='A2 Pi Client')
parser.add_argument('--server', default=config.SERVER_ADDRESS, help='WebSocket server hostname or IP')
parser.add_argument('--port', type=int, default=config.SERVER_PORT, help='WebSocket server port')
parser.add_argument('--debug', action='store_true', help='Enable debug logging')
parser.add_argument('--simulation', action='store_true', help='Run in simulation mode without hardware')
args = parser.parse_args()

# Set log level
if args.debug:
    logger.setLevel(logging.DEBUG)

# Configuration
SERVER_ADDRESS = args.server
SERVER_PORT = args.port
SIMULATION_MODE = args.simulation or config.SIMULATION_MODE
WS_URL = f"ws://{SERVER_ADDRESS}:{SERVER_PORT}/pi"
RECONNECT_DELAY = 5
MAX_RECONNECT_ATTEMPTS = 10

class WebSocketClient:
    def __init__(self, camera_manager, servo_controller, audio_detector=None):
        """Initialize the WebSocket client"""
        self.camera = camera_manager
        self.servo = servo_controller
        self.audio = audio_detector
        
        self.websocket = None
        self.connected = False
        self.stopping = False
        self.reconnect_attempt = 1
        
        self.frame_count = 0
        self.last_frame_time = 0
        self.last_telemetry_time = 0
        
        # Set up a queue for frames
        self.frame_queue = asyncio.Queue(maxsize=5)
    
    async def connect(self):
        """Connect to the WebSocket server"""
        try:
            # Check server connectivity first
            if not await self.check_server_connectivity():
                logger.warning("Server connectivity check failed, but still trying to connect...")
            
            # Connect with timeout
            logger.info(f"Connecting to {WS_URL}...")
            self.websocket = await asyncio.wait_for(
                websockets.connect(
                    WS_URL,
                    ping_interval=None,  # We'll handle pings manually
                    close_timeout=2,     # Quicker close on errors
                    max_size=20*1024*1024,  # 20MB max message size
                ),
                timeout=10  # 10 second timeout
            )
            
            self.connected = True
            logger.info("Connected to WebSocket server successfully")
            
            # Send hello message
            hello_message = json.dumps({
                "type": "hello",
                "client": "pi",
                "timestamp": time.time(),
                "hostname": socket.gethostname(),
                "simulation_mode": SIMULATION_MODE
            })
            
            logger.info("Sending hello message to server")
            await self.websocket.send(hello_message)
            
            return True
        
        except asyncio.TimeoutError:
            logger.error("Connection timeout")
            self.connected = False
            return False
        except Exception as e:
            logger.error(f"Failed to connect: {e}")
            logger.error(traceback.format_exc())
            self.connected = False
            return False
    
    async def check_server_connectivity(self):
        """Check if the server is reachable"""
        try:
            # Try to resolve hostname
            ip = socket.gethostbyname(SERVER_ADDRESS)
            logger.info(f"Resolved {SERVER_ADDRESS} to {ip}")
            
            # Try to connect to the port
            s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            s.settimeout(2)
            s.connect((ip, SERVER_PORT))
            s.close()
            logger.info(f"Successfully connected to {ip}:{SERVER_PORT}")
            return True
        except Exception as e:
            logger.error(f"Connectivity check failed: {e}")
            return False
    
    async def process_frames(self):
        """Process and send frames from the camera"""
        while self.connected and not self.stopping:
            try:
                # Get a frame from the camera
                frame = self.camera.get_color_frame()
                
                if frame is None:
                    logger.warning("Failed to get frame from camera")
                    await asyncio.sleep(0.1)
                    continue
                
                # Increment frame count
                self.frame_count += 1
                
                # Only process every N frames to reduce load
                if self.frame_count % config.SEND_EVERY_N_FRAMES == 0:
                    # Calculate FPS
                    now = time.time()
                    if self.last_frame_time > 0:
                        fps = 1.0 / (now - self.last_frame_time)
                    else:
                        fps = 30.0
                    self.last_frame_time = now
                    
                    # Encode frame to JPEG
                    encode_params = [cv2.IMWRITE_JPEG_QUALITY, config.JPEG_QUALITY]
                    ret, jpeg = cv2.imencode('.jpg', frame, encode_params)
                    
                    if not ret:
                        logger.error("Failed to encode frame")
                        continue
                    
                    # Convert to base64 for sending via WebSocket
                    frame_data = base64.b64encode(jpeg.tobytes()).decode('utf-8')
                    
                    # Get additional camera data if available
                    camera_info = {}
                    depth_data = None
                    
                    if hasattr(self.camera, 'get_camera_info'):
                        camera_info = self.camera.get_camera_info()
                    
                    if hasattr(self.camera, 'get_depth_frame'):
                        depth_frame = self.camera.get_depth_frame()
                        if depth_frame is not None:
                            # Encode depth frame as base64
                            depth_png = cv2.imencode('.png', depth_frame)[1].tobytes()
                            depth_data = base64.b64encode(depth_png).decode('utf-8')
                    
                    # Create frame message
                    frame_message = {
                        "type": "frame",
                        "frame_id": self.frame_count,
                        "timestamp": time.time(),
                        "image": frame_data,
                        "depth_data": depth_data,
                        "camera_info": {
                            "model": camera_info.get("name", "D455"),
                            "serial": camera_info.get("serial", "unknown"),
                            "resolution": [self.camera.width, self.camera.height]
                        },
                        "depth_scale": 0.001,  # Meters per unit
                        "fps": fps
                    }
                    
                    # Send the frame
                    await self.websocket.send(json.dumps(frame_message))
                    logger.debug(f"Sent frame {self.frame_count}")
                
                # Sleep briefly to avoid overwhelming the system
                await asyncio.sleep(0.01)
            
            except websockets.exceptions.ConnectionClosed:
                logger.warning("Connection closed while sending frame")
                self.connected = False
                break
            except Exception as e:
                logger.error(f"Error in frame processing: {e}")
                logger.error(traceback.format_exc())
                await asyncio.sleep(0.5)
    
    async def send_telemetry(self):
        """Send periodic telemetry data"""
        while self.connected and not self.stopping:
            try:
                # Only send telemetry every few seconds
                now = time.time()
                if now - self.last_telemetry_time < config.TELEMETRY_INTERVAL:
                    await asyncio.sleep(0.1)
                    continue
                
                self.last_telemetry_time = now
                
                # Collect telemetry data
                telemetry = {
                    "type": "telemetry",
                    "timestamp": now,
                    "system": {
                        "hostname": socket.gethostname(),
                        "uptime": self.get_uptime(),
                        "temperature": self.get_cpu_temperature(),
                        "memory": self.get_memory_usage()
                    },
                    "servo": self.servo.get_status(),
                }
                
                # Add audio data if available
                if self.audio:
                    audio_levels = self.audio.read_all_microphones()
                    telemetry["audio"] = {
                        "levels": audio_levels,
                        "direction": self.audio.detect_direction()
                    }
                
                # Send telemetry
                await self.websocket.send(json.dumps(telemetry))
                logger.debug("Sent telemetry data")
            
            except websockets.exceptions.ConnectionClosed:
                logger.warning("Connection closed while sending telemetry")
                self.connected = False
                break
            except Exception as e:
                logger.error(f"Error sending telemetry: {e}")
                logger.error(traceback.format_exc())
                await asyncio.sleep(0.5)
    
    async def receive_data(self):
        """Receive and handle incoming messages from the server"""
        while self.connected and not self.stopping:
            try:
                # Receive message
                message = await self.websocket.recv()
                
                # Parse JSON
                try:
                    data = json.loads(message)
                    message_type = data.get("type", "unknown")
                    
                    logger.debug(f"Received message of type: {message_type}")
                    
                    if message_type == "control":
                        # Handle control message
                        action = data.get("action")
                        
                        if action == "move_servos":
                            # Update servo positions
                            params = data.get("params", {})
                            
                            if "pan" in params or "tilt" in params or "roll" in params:
                                # Update servo positions
                                pan = params.get("pan")
                                tilt = params.get("tilt")
                                roll = params.get("roll")
                                
                                # Move servos
                                result = self.servo.set_position(pan=pan, tilt=tilt, roll=roll)
                                
                                # Send confirmation
                                response = {
                                    "type": "control_response",
                                    "action": "move_servos",
                                    "success": True,
                                    "position": {
                                        "pan": result[0],
                                        "tilt": result[1],
                                        "roll": result[2]
                                    },
                                    "timestamp": time.time()
                                }
                                
                                await self.websocket.send(json.dumps(response))
                        
                        elif action == "center_servos":
                            # Center all servos
                            result = self.servo.center()
                            
                            # Send confirmation
                            response = {
                                "type": "control_response",
                                "action": "center_servos",
                                "success": True,
                                "position": {
                                    "pan": result[0],
                                    "tilt": result[1],
                                    "roll": result[2]
                                },
                                "timestamp": time.time()
                            }
                            
                            await self.websocket.send(json.dumps(response))
                    
                    elif message_type == "ping":
                        # Respond with pong
                        await self.websocket.send(json.dumps({
                            "type": "pong",
                            "timestamp": time.time()
                        }))
                    
                    elif message_type == "detection_result":
                        # Handle detection results
                        frame_id = data.get("frame_id")
                        detections = data.get("detections", [])
                        
                        if detections:
                            # Use detections for tracking or other purposes
                            logger.debug(f"Received {len(detections)} detections for frame {frame_id}")
                    
                    elif message_type == "welcome":
                        # Server acknowledged our connection
                        logger.info("Server acknowledged connection with welcome message")
                
                except json.JSONDecodeError:
                    logger.error("Received invalid JSON")
            
            except websockets.exceptions.ConnectionClosed:
                logger.warning("Connection closed during receive")
                self.connected = False
                break
            except Exception as e:
                logger.error(f"Error receiving data: {e}")
                logger.error(traceback.format_exc())
                await asyncio.sleep(0.5)
    
    async def maintain_connection(self):
        """Send periodic heartbeats to keep the connection alive"""
        while self.connected and not self.stopping:
            try:
                # Send a ping every 30 seconds
                await asyncio.sleep(30)
                
                if self.connected:
                    await self.websocket.send(json.dumps({
                        "type": "ping",
                        "timestamp": time.time()
                    }))
                    logger.debug("Sent ping")
            
            except websockets.exceptions.ConnectionClosed:
                logger.warning("Connection closed during heartbeat")
                self.connected = False
                break
            except Exception as e:
                logger.error(f"Error sending heartbeat: {e}")
                await asyncio.sleep(0.5)
    
    async def run_client(self):
        """Main method to run the WebSocket client"""
        logger.info("Starting WebSocket client...")
        
        while not self.stopping:
            try:
                # Connect to server
                connected = await self.connect()
                
                if connected:
                    # Start tasks
                    tasks = [
                        asyncio.create_task(self.process_frames()),
                        asyncio.create_task(self.send_telemetry()),
                        asyncio.create_task(self.receive_data()),
                        asyncio.create_task(self.maintain_connection())
                    ]
                    
                    # Wait for any task to complete (which typically means an error occurred)
                    _, pending = await asyncio.wait(
                        tasks,
                        return_when=asyncio.FIRST_COMPLETED
                    )
                    
                    # Cancel pending tasks
                    for task in pending:
                        task.cancel()
                    
                    # If we get here, the connection was lost
                    self.connected = False
                
                # Try to reconnect if not stopping
                if not self.stopping:
                    self.reconnect_attempt += 1
                    
                    if self.reconnect_attempt > MAX_RECONNECT_ATTEMPTS:
                        logger.error(f"Exceeded maximum reconnect attempts ({MAX_RECONNECT_ATTEMPTS}), giving up")
                        return
                    
                    # Wait with exponential backoff
                    delay = min(RECONNECT_DELAY * (1.5 ** (self.reconnect_attempt - 1)), 60)
                    jitter = random.uniform(0, 2)
                    total_delay = delay + jitter
                    
                    logger.info(f"Reconnecting in {total_delay:.1f} seconds (attempt {self.reconnect_attempt}/{MAX_RECONNECT_ATTEMPTS})...")
                    await asyncio.sleep(total_delay)
            
            except Exception as e:
                logger.error(f"Error in client main loop: {e}")
                logger.error(traceback.format_exc())
                await asyncio.sleep(5)
    
    async def stop(self):
        """Stop the client gracefully"""
        logger.info("Stopping client...")
        self.stopping = True
        
        # Close WebSocket connection
        if self.websocket:
            await self.websocket.close()
    
    def get_uptime(self):
        """Get system uptime in seconds"""
        try:
            with open('/proc/uptime', 'r') as f:
                uptime_seconds = float(f.readline().split()[0])
            return uptime_seconds
        except:
            return 0
    
    def get_cpu_temperature(self):
        """Get CPU temperature in Celsius"""
        try:
            temp = 0
            if os.path.exists('/sys/class/thermal/thermal_zone0/temp'):
                with open('/sys/class/thermal/thermal_zone0/temp') as f:
                    temp = float(f.read()) / 1000.0
            return temp
        except:
            return 0
    
    def get_memory_usage(self):
        """Get memory usage statistics"""
        try:
            with open('/proc/meminfo', 'r') as f:
                lines = f.readlines()
            
            mem_info = {}
            for line in lines:
                if ":" in line:
                    key, value = line.split(':')
                    value = value.strip()
                    if value.endswith('kB'):
                        value = int(value[:-2]) * 1024
                    mem_info[key.strip()] = value
            
            total = int(mem_info.get('MemTotal', 0))
            free = int(mem_info.get('MemFree', 0))
            available = int(mem_info.get('MemAvailable', 0))
            
            if total > 0:
                used_percent = 100 * (total - available) / total
            else:
                used_percent = 0
            
            return {
                "total": total,
                "free": free,
                "available": available,
                "used_percent": used_percent
            }
        except:
            return {
                "total": 0,
                "free": 0,
                "available": 0,
                "used_percent": 0
            }

def init_system():
    """Initialize all system components"""
    global SIMULATION_MODE
    logger.info("Initializing system components...")
    
    # Initialize camera
    logger.info("Initializing camera...")
    camera_manager = RealSenseCamera(
        width=config.FRAME_WIDTH,
        height=config.FRAME_HEIGHT,
        fps=config.FRAME_RATE,
        simulation_mode=SIMULATION_MODE
    )
    success = camera_manager.initialize()
    
    if success:
        logger.info("Camera initialized successfully")
        camera_manager.start_streaming()
    else:
        logger.error("Failed to initialize camera")
        if not SIMULATION_MODE:
            logger.warning("Falling back to simulation mode")
            SIMULATION_MODE = True
            camera_manager = RealSenseCamera(
                width=config.FRAME_WIDTH,
                height=config.FRAME_HEIGHT,
                fps=config.FRAME_RATE,
                simulation_mode=True
            )
            camera_manager.initialize()
            camera_manager.start_streaming()
    
    # Initialize servo controller
    logger.info("Initializing servo controller...")
    try:
        servo_config = {
            'servo_pins': {
                'pan': config.PAN_CHANNEL,
                'tilt': config.TILT_CHANNEL
            },
            'min_pulse_width': 0.5,
            'max_pulse_width': 2.5,
            'frequency': 50
        }
        servo_controller = ServoController(config=servo_config)
        servo_controller.initialize()
        logger.info("Servo controller initialized")
    except Exception as e:
        logger.error(f"Failed to initialize servo controller: {e}")
        logger.error(traceback.format_exc())
        logger.warning("Using simulated servo controller")
        servo_controller = ServoController()
    
    # Initialize audio detector
    logger.info("Initializing audio detector...")
    try:
        audio_detector = AudioDetector(simulation_mode=SIMULATION_MODE)
        audio_detector.initialize()
        logger.info("Audio detector initialized")
    except Exception as e:
        logger.error(f"Failed to initialize audio detector: {e}")
        logger.warning("Audio detection will not be available")
        audio_detector = None
    
    # Initialize WebSocket client
    logger.info("Initializing WebSocket client...")
    websocket_client = WebSocketClient(
        camera_manager=camera_manager,
        servo_controller=servo_controller,
        audio_detector=audio_detector
    )
    
    return camera_manager, servo_controller, audio_detector, websocket_client

def main():
    """Main entry point"""
    # Display startup information
    logger.info(f"A2 Pi Client v{config.VERSION}")
    logger.info(f"Server: {SERVER_ADDRESS}:{SERVER_PORT}")
    logger.info(f"Simulation mode: {SIMULATION_MODE}")
    
    # Initialize system components
    camera_manager, servo_controller, audio_detector, websocket_client = init_system()
    
    try:
        # Create and get event loop
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        # Run the client
        loop.run_until_complete(websocket_client.run_client())
    except KeyboardInterrupt:
        logger.info("Client terminated by user")
    except Exception as e:
        logger.error(f"Fatal error: {e}")
        logger.error(traceback.format_exc())
    finally:
        # Shutdown resources
        logger.info("Shutting down...")
        
        # Stop WebSocket client
        try:
            loop.run_until_complete(websocket_client.stop())
        except:
            pass
        
        # Stop camera
        try:
            camera_manager.stop_streaming()
        except:
            pass
        
        # Reset servos to center position
        try:
            servo_controller.center()
            servo_controller.shutdown()
        except:
            pass
        
        logger.info("Shutdown complete")

if __name__ == "__main__":
    main()


================================================================================
FILE: ./client/message_handler.py
================================================================================

#!/usr/bin/env python3
"""
Message processing logic for the Pi client.
"""

import json
import logging

class MessageHandler:
    def __init__(self, config):
        """Initialize the message handler with configuration."""
        self.config = config
        self.logger = logging.getLogger(__name__)
        
    def send(self, message):
        """
        Send a message to the server.
        
        Args:
            message (dict): The message to send
            
        Returns:
            bool: True if successful, False otherwise
        """
        try:
            # Serialize the message
            serialized = json.dumps(message)
            
            # Send the message (implement actual sending mechanism)
            self.logger.info(f"Sending message: {serialized}")
            
            # For now just log it
            return True
        except Exception as e:
            self.logger.error(f"Failed to send message: {e}")
            return False
    
    def receive(self):
        """
        Receive a message from the server.
        
        Returns:
            dict: The received message or None if no message available
        """
        try:
            # Implement actual message receiving here
            self.logger.debug("Checking for messages")
            
            # Mock received message for now
            return None
        except Exception as e:
            self.logger.error(f"Failed to receive message: {e}")
            return None
    
    def process(self, message):
        """
        Process a received message.
        
        Args:
            message (dict): The message to process
            
        Returns:
            dict: Response message if any
        """
        if not message:
            return None
            
        try:
            # Parse message type and respond accordingly
            msg_type = message.get('type', '')
            
            if msg_type == 'command':
                return self._handle_command(message)
            elif msg_type == 'query':
                return self._handle_query(message)
            else:
                self.logger.warning(f"Unknown message type: {msg_type}")
                return {'status': 'error', 'error': 'Unknown message type'}
                
        except Exception as e:
            self.logger.error(f"Error processing message: {e}")
            return {'status': 'error', 'error': str(e)}
    
    def _handle_command(self, message):
        """Handle command messages."""
        command = message.get('command', '')
        self.logger.info(f"Handling command: {command}")
        
        # Implement command handling logic
        return {'status': 'success', 'command': command}
    
    def _handle_query(self, message):
        """Handle query messages."""
        query = message.get('query', '')
        self.logger.info(f"Handling query: {query}")
        
        # Implement query handling logic
        return {'status': 'success', 'query': query, 'result': None} 


================================================================================
FILE: ./config.py
================================================================================

"""
Configuration file for the A2 Pi Client
"""

import os
import logging

# Version
VERSION = "1.0.0"

# System settings
DEBUG = os.environ.get('DEBUG', 'False').lower() == 'true'
LOG_LEVEL = logging.DEBUG if DEBUG else logging.INFO
SIMULATION_MODE = os.environ.get('SIMULATION_MODE', 'False').lower() == 'true'

# Server settings
SERVER_ADDRESS = os.environ.get('SERVER_ADDRESS', '192.168.50.86')  # WebSocket server address
SERVER_PORT = int(os.environ.get('SERVER_PORT', '5000'))

# Camera settings
FRAME_WIDTH = int(os.environ.get('FRAME_WIDTH', '640'))
FRAME_HEIGHT = int(os.environ.get('FRAME_HEIGHT', '480'))
FRAME_RATE = int(os.environ.get('FRAME_RATE', '30'))
JPEG_QUALITY = int(os.environ.get('JPEG_QUALITY', '75'))
SEND_EVERY_N_FRAMES = int(os.environ.get('SEND_EVERY_N_FRAMES', '2'))  # Send every 2nd frame

# Telemetry settings
TELEMETRY_INTERVAL = float(os.environ.get('TELEMETRY_INTERVAL', '1.0'))  # Send telemetry every 1 second

# Servo settings
PAN_CHANNEL = 0
TILT_CHANNEL = 1
ROLL_CHANNEL = 2
PAN_LIMITS = (-80, 80)
TILT_LIMITS = (-45, 45)
ROLL_LIMITS = (-30, 30)


================================================================================
FILE: ./hardware/audio/audio_detector.py
================================================================================

#!/usr/bin/env python3
"""
Audio detection module for the Pi client.
"""

import logging
import time
import threading
import numpy as np

# Placeholder for audio libraries
# In a real implementation, you would use:
# import pyaudio
# import librosa

class AudioDetector:
    """Interface for audio detection and processing."""
    
    def __init__(self, config=None):
        """
        Initialize the audio detector with configuration.
        
        Args:
            config (dict, optional): Audio detector configuration
        """
        self.config = config or {}
        self.logger = logging.getLogger(__name__)
        self.running = False
        self.thread = None
        
        # Default audio settings
        self.sample_rate = self.config.get('sample_rate', 16000)
        self.chunk_size = self.config.get('chunk_size', 1024)
        self.channels = self.config.get('channels', 1)
        self.format = self.config.get('format', 'int16')
        
        # Detection settings
        self.threshold = self.config.get('threshold', 0.5)
        self.min_duration = self.config.get('min_duration', 0.5)  # Minimum sound duration in seconds
        
        # Callback for when audio is detected
        self.on_audio_detected = None
        
    def start(self):
        """Start audio detection in a background thread."""
        if self.running:
            self.logger.warning("Audio detector already running")
            return True
            
        try:
            self.logger.info("Starting audio detector...")
            
            # In a real implementation:
            # self.stream = pyaudio.PyAudio().open(
            #     format=pyaudio.paInt16,
            #     channels=self.channels,
            #     rate=self.sample_rate,
            #     input=True,
            #     frames_per_buffer=self.chunk_size
            # )
            
            self.running = True
            self.thread = threading.Thread(target=self._detection_loop)
            self.thread.daemon = True
            self.thread.start()
            
            self.logger.info("Audio detector started")
            return True
        except Exception as e:
            self.logger.error(f"Failed to start audio detector: {e}")
            return False
            
    def stop(self):
        """Stop audio detection."""
        if not self.running:
            return
            
        try:
            self.logger.info("Stopping audio detector...")
            self.running = False
            
            if self.thread:
                self.thread.join(timeout=2.0)
                
            # In a real implementation:
            # if hasattr(self, 'stream') and self.stream:
            #     self.stream.stop_stream()
            #     self.stream.close()
            
            self.logger.info("Audio detector stopped")
        except Exception as e:
            self.logger.error(f"Error stopping audio detector: {e}")
            
    def _detection_loop(self):
        """Background thread for continuous audio detection."""
        detection_active = False
        detection_start_time = 0
        
        self.logger.info("Audio detection loop started")
        
        while self.running:
            try:
                # In a real implementation:
                # audio_data = np.frombuffer(self.stream.read(self.chunk_size), dtype=np.int16)
                # volume = np.abs(audio_data).mean() / 32768.0  # Normalize to 0.0-1.0
                
                # Mock audio detection
                time.sleep(0.1)
                volume = np.random.random() * 0.2  # Random volume between 0 and 0.2
                
                # Simulate periodic sound for testing
                if time.time() % 10 < 2:  # 2 seconds of sound every 10 seconds
                    volume = 0.8  # Higher than threshold
                
                if volume > self.threshold:
                    if not detection_active:
                        detection_active = True
                        detection_start_time = time.time()
                        self.logger.debug(f"Sound detected (volume: {volume:.2f})")
                else:
                    if detection_active:
                        duration = time.time() - detection_start_time
                        if duration >= self.min_duration:
                            self.logger.info(f"Sound detected for {duration:.2f}s")
                            if self.on_audio_detected:
                                self.on_audio_detected(duration)
                        detection_active = False
                        
            except Exception as e:
                self.logger.error(f"Error in audio detection loop: {e}")
                time.sleep(1.0)  # Avoid tight loop on error
                
        self.logger.info("Audio detection loop ended")
        
    def set_detection_callback(self, callback):
        """
        Set callback function for audio detection events.
        
        Args:
            callback (callable): Function to call when audio is detected
                The function should accept a single parameter (duration in seconds)
        """
        self.on_audio_detected = callback
        
    def set_threshold(self, threshold):
        """
        Set the volume threshold for audio detection.
        
        Args:
            threshold (float): Volume threshold between 0.0 and 1.0
        """
        self.threshold = max(0.0, min(1.0, threshold))
        self.logger.info(f"Audio detection threshold set to {self.threshold:.2f}") 


================================================================================
FILE: ./hardware/camera/realsense_camera.py
================================================================================

#!/usr/bin/env python3
"""
RealSense camera interface for the Pi client.
"""

import logging
import numpy as np
import time

# Import RealSense SDK
try:
    import pyrealsense2 as rs
    REALSENSE_AVAILABLE = True
except ImportError:
    REALSENSE_AVAILABLE = False
    logging.warning("pyrealsense2 not available, using simulation mode")

class RealSenseCamera:
    """Interface for Intel RealSense camera."""
    
    def __init__(self, width=640, height=480, fps=30, simulation_mode=False, depth_enabled=True):
        """
        Initialize the RealSense camera with configuration.
        
        Args:
            width (int): Frame width
            height (int): Frame height
            fps (int): Frames per second
            simulation_mode (bool): Whether to use simulation mode
            depth_enabled (bool): Whether to enable depth stream
        """
        self.width = width
        self.height = height
        self.fps = fps
        self.depth_enabled = depth_enabled
        self.simulation_mode = simulation_mode or not REALSENSE_AVAILABLE
        
        self.logger = logging.getLogger(__name__)
        self.pipeline = None
        self.config = None
        self.running = False
        
    def initialize(self):
        """Initialize the camera resources."""
        if self.simulation_mode:
            self.logger.info("Initializing RealSense camera in simulation mode")
            return True
            
        try:
            self.logger.info(f"Initializing RealSense camera: {self.width}x{self.height}@{self.fps}fps")
            self.pipeline = rs.pipeline()
            self.config = rs.config()
            
            # Try to find a connected device
            ctx = rs.context()
            devices = ctx.query_devices()
            if len(devices) == 0:
                self.logger.error("No RealSense devices found")
                return False
                
            self.logger.info(f"Found {len(devices)} RealSense device(s)")
            device = devices[0]
            self.logger.info(f"Using device: {device.get_info(rs.camera_info.name)}")
            
            return True
        except Exception as e:
            self.logger.error(f"Failed to initialize RealSense camera: {e}")
            return False
    
    def start_streaming(self):
        """Start the camera streaming."""
        if self.running:
            self.logger.warning("Camera already running")
            return True
            
        if self.simulation_mode:
            self.logger.info("Starting RealSense camera simulation")
            self.running = True
            return True
            
        try:
            self.logger.info("Starting RealSense camera streaming...")
            
            # Configure streams
            self.config.enable_stream(rs.stream.color, self.width, self.height, rs.format.bgr8, self.fps)
            if self.depth_enabled:
                self.config.enable_stream(rs.stream.depth, self.width, self.height, rs.format.z16, self.fps)
            
            # Start streaming
            self.pipeline.start(self.config)
            
            self.running = True
            self.logger.info("RealSense camera streaming started")
            return True
        except Exception as e:
            self.logger.error(f"Failed to start RealSense camera streaming: {e}")
            return False
            
    def stop_streaming(self):
        """Stop the camera streaming."""
        if not self.running:
            return
            
        try:
            self.logger.info("Stopping RealSense camera streaming...")
            
            if not self.simulation_mode:
                self.pipeline.stop()
            
            self.running = False
            self.logger.info("RealSense camera streaming stopped")
        except Exception as e:
            self.logger.error(f"Error stopping RealSense camera: {e}")
            
    def get_color_frame(self):
        """
        Get the latest color frame from the camera.
        
        Returns:
            numpy.ndarray: Color image as a NumPy array, or None on failure
        """
        if not self.running:
            self.logger.error("Camera not running")
            return None
            
        try:
            if self.simulation_mode:
                # Mock implementation returns a black image
                return np.zeros((self.height, self.width, 3), dtype=np.uint8)
            
            # Get actual frame from camera
            frames = self.pipeline.wait_for_frames()
            color_frame = frames.get_color_frame()
            
            if not color_frame:
                self.logger.warning("Empty color frame received")
                return None
                
            return np.asanyarray(color_frame.get_data())
        except Exception as e:
            self.logger.error(f"Error getting color frame: {e}")
            return None
            
    def get_depth_frame(self):
        """
        Get the latest depth frame from the camera.
        
        Returns:
            numpy.ndarray: Depth image as a NumPy array, or None on failure
        """
        if not self.running or not self.depth_enabled:
            self.logger.error("Depth stream not available")
            return None
            
        try:
            if self.simulation_mode:
                # Mock implementation returns a zero depth image
                return np.zeros((self.height, self.width), dtype=np.uint16)
            
            # Get actual depth frame
            frames = self.pipeline.wait_for_frames()
            depth_frame = frames.get_depth_frame()
            
            if not depth_frame:
                self.logger.warning("Empty depth frame received")
                return None
                
            return np.asanyarray(depth_frame.get_data())
        except Exception as e:
            self.logger.error(f"Error getting depth frame: {e}")
            return None
            
    def get_camera_info(self):
        """
        Get camera information.
        
        Returns:
            dict: Camera information
        """
        info = {
            "width": self.width,
            "height": self.height,
            "fps": self.fps,
            "depth_enabled": self.depth_enabled,
            "simulation_mode": self.simulation_mode
        }
        
        if not self.simulation_mode and self.running:
            try:
                # Get device information
                ctx = rs.context()
                devices = ctx.query_devices()
                if devices:
                    device = devices[0]
                    info["name"] = device.get_info(rs.camera_info.name)
                    info["serial"] = device.get_info(rs.camera_info.serial_number)
                    info["firmware"] = device.get_info(rs.camera_info.firmware_version)
            except Exception as e:
                self.logger.error(f"Error getting camera info: {e}")
        
        return info 


================================================================================
FILE: ./hardware/camera/test_d455.py
================================================================================

#!/usr/bin/env python3
"""
Test script for Intel RealSense D455 camera on Raspberry Pi 5
This script verifies that the D455 camera is properly connected and functioning
"""

import sys
import time
import argparse
import os

# Parse command-line arguments
parser = argparse.ArgumentParser(description="Intel RealSense D455 Camera Test")
parser.add_argument('--record', action='store_true', help='Record images to disk')
parser.add_argument('--duration', type=int, default=30, help='Duration of the test in seconds')
args = parser.parse_args()

# Import required libraries
try:
    import numpy as np
    import cv2
    print("OpenCV and NumPy libraries loaded successfully")
except ImportError as e:
    print(f"Error: {e}")
    print("Please install OpenCV and NumPy: pip install opencv-python numpy")
    sys.exit(1)

# Try to import pyrealsense2
try:
    import pyrealsense2 as rs
    print("Intel RealSense library loaded successfully")
    # Check version if available, otherwise just note that it's loaded
    try:
        version = rs.__version__
        print(f"Library version: {version}")
    except AttributeError:
        print("Library version: Unknown (version attribute not available)")
except ImportError:
    print("Error: Intel RealSense library (pyrealsense2) not found")
    print("Please install it using: pip install pyrealsense2")
    print("For Raspberry Pi, you may need to build from source or use a pre-built wheel.")
    print("See: https://github.com/IntelRealSense/librealsense/tree/master/wrappers/python")
    sys.exit(1)

# Add at beginning of script
os.environ["OPENCV_VIDEOIO_MSMF_ENABLE_HW_TRANSFORMS"] = "0"

# Function to colorize depth frame
def colorize_depth(depth_image, min_depth=0.1, max_depth=10.0):
    """Convert depth image to color for better visualization"""
    depth_colormap = cv2.applyColorMap(
        cv2.convertScaleAbs(depth_image, alpha=255/max_depth), 
        cv2.COLORMAP_JET
    )
    return depth_colormap

# Setup the RealSense pipeline
try:
    print("Initializing RealSense pipeline...")
    
    # Create pipeline
    pipeline = rs.pipeline()
    
    # Create a config object
    config = rs.config()
    
    # Check if any devices are connected
    ctx = rs.context()
    devices = ctx.query_devices()
    if len(list(devices)) == 0:
        print("No RealSense devices detected. Please connect a device and try again.")
        sys.exit(1)
    
    # Print information about connected devices
    print(f"Found {len(list(devices))} RealSense device(s):")
    for i, dev in enumerate(devices):
        print(f"  Device {i+1}:")
        print(f"    Name: {dev.get_info(rs.camera_info.name)}")
        print(f"    Serial Number: {dev.get_info(rs.camera_info.serial_number)}")
        print(f"    Product Line: {dev.get_info(rs.camera_info.product_line)}")
        
    # Configure streams
    print("Configuring streams...")
    # Lower resolution for better performance on Raspberry Pi
    color_width, color_height = 640, 480  
    depth_width, depth_height = 640, 480
    fps = 30
    
    # Enable streams
    config.enable_stream(rs.stream.color, color_width, color_height, rs.format.bgr8, fps)
    config.enable_stream(rs.stream.depth, depth_width, depth_height, rs.format.z16, fps)
    
    # Start streaming
    print("Starting pipeline...")
    profile = pipeline.start(config)
    
    # Get the device
    device = profile.get_device()
    print(f"Using device: {device.get_info(rs.camera_info.name)}")
    
    # Get depth sensor
    depth_sensor = device.first_depth_sensor()
    depth_scale = depth_sensor.get_depth_scale()
    print(f"Depth Scale: {depth_scale}")
    
    # Create align object
    align_to = rs.stream.color
    align = rs.align(align_to)
    
    print("Camera initialized successfully!")
    print(f"Running test for {args.duration} seconds...")
    
    # Create a window for displaying the images
    cv2.namedWindow('RealSense D455 Test', cv2.WINDOW_NORMAL)
    cv2.resizeWindow('RealSense D455 Test', color_width + depth_width, color_height)
    
    # Variables for statistics
    frame_count = 0
    start_time = time.time()
    depth_values = []
    
    # Create directory for saving images if needed
    if args.record:
        from datetime import datetime
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        save_dir = f"d455_capture_{timestamp}"
        
        if not os.path.exists(save_dir):
            os.makedirs(save_dir)
            
        print(f"Recording images to: {save_dir}/")
    
    # Main loop
    try:
        while time.time() - start_time < args.duration:
            # Wait for a coherent pair of frames: depth and color
            frames = pipeline.wait_for_frames()
            
            # Align the depth frame to color frame
            aligned_frames = align.process(frames)
            
            # Get aligned frames
            depth_frame = aligned_frames.get_depth_frame()
            color_frame = aligned_frames.get_color_frame()
            
            if not depth_frame or not color_frame:
                print("Warning: Invalid frame received")
                continue
            
            # Convert to numpy arrays
            depth_image = np.asanyarray(depth_frame.get_data())
            color_image = np.asanyarray(color_frame.get_data())
            
            # Get some depth data for statistics
            if frame_count % 30 == 0:  # Sample once per second
                center_x, center_y = depth_width // 2, depth_height // 2
                center_distance = depth_frame.get_distance(center_x, center_y)
                if center_distance > 0:
                    depth_values.append(center_distance)
                    
            # Colorize depth for display
            depth_colormap = colorize_depth(depth_image)
            
            # Combine images side by side
            combined_image = np.hstack((color_image, depth_colormap))
            
            # Add frame counter and fps
            elapsed_time = time.time() - start_time
            fps = frame_count / elapsed_time if elapsed_time > 0 else 0
            cv2.putText(combined_image, f"Frame: {frame_count} | FPS: {fps:.1f}", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            
            # Add center distance
            if depth_values:
                cv2.putText(combined_image, f"Center distance: {depth_values[-1]:.2f}m", 
                           (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            
            # Show images
            cv2.imshow('RealSense D455 Test', combined_image)
            
            # Save images if recording is enabled
            if args.record and frame_count % 5 == 0:  # Save every 5th frame
                cv2.imwrite(f"{save_dir}/color_{frame_count:04d}.jpg", color_image)
                cv2.imwrite(f"{save_dir}/depth_{frame_count:04d}.png", depth_image)
            
            # Increment frame counter
            frame_count += 1
            
            # Exit on ESC key
            key = cv2.waitKey(1)
            if key == 27:  # ESC
                break
                
    finally:
        # Calculate and display statistics
        end_time = time.time()
        elapsed_time = end_time - start_time
        avg_fps = frame_count / elapsed_time if elapsed_time > 0 else 0
        
        print("\nTest Results:")
        print(f"  Ran for {elapsed_time:.1f} seconds")
        print(f"  Processed {frame_count} frames")
        print(f"  Average FPS: {avg_fps:.1f}")
        
        if depth_values:
            avg_depth = sum(depth_values) / len(depth_values)
            print(f"  Average center distance: {avg_depth:.2f}m")
            
        print("Stopping pipeline...")
        pipeline.stop()
        cv2.destroyAllWindows()
        
        print("Test completed successfully!")
        
except Exception as e:
    import traceback
    print(f"Error during RealSense camera test: {e}")
    print(traceback.format_exc())
    sys.exit(1) 


================================================================================
FILE: ./hardware/servo/controller.py
================================================================================

#!/usr/bin/env python3
"""
Servo motor controller interface.
"""

import logging
import time

# Placeholder for GPIO control
# In a real implementation on a Raspberry Pi, you would use:
# import RPi.GPIO as GPIO

class ServoController:
    """Interface for controlling servo motors."""
    
    def __init__(self, config=None):
        """
        Initialize the servo controller with configuration.
        
        Args:
            config (dict, optional): Servo controller configuration
        """
        self.config = config or {}
        self.logger = logging.getLogger(__name__)
        self.initialized = False
        
        # Default configuration
        self.servo_pins = self.config.get('servo_pins', {
            'pan': 12,   # Default GPIO pin for pan servo
            'tilt': 13,  # Default GPIO pin for tilt servo
        })
        self.min_pulse_width = self.config.get('min_pulse_width', 0.5)  # in ms
        self.max_pulse_width = self.config.get('max_pulse_width', 2.5)  # in ms
        self.frequency = self.config.get('frequency', 50)  # in Hz
        
        # Current position tracking
        self.current_positions = {
            'pan': 90,   # Default mid-position (0-180 degrees)
            'tilt': 90,  # Default mid-position (0-180 degrees)
        }
        
    def initialize(self):
        """Initialize the GPIO and servo hardware."""
        if self.initialized:
            return True
            
        try:
            self.logger.info("Initializing servo controller...")
            
            # In a real implementation:
            # GPIO.setmode(GPIO.BCM)
            # for servo_name, pin in self.servo_pins.items():
            #     GPIO.setup(pin, GPIO.OUT)
            #     # Create PWM instance for each servo
            #     self.pwm[servo_name] = GPIO.PWM(pin, self.frequency)
            #     self.pwm[servo_name].start(0)  # Start with 0% duty cycle
            
            # For now, just mock initialization
            self.initialized = True
            self.logger.info("Servo controller initialized")
            return True
        except Exception as e:
            self.logger.error(f"Failed to initialize servo controller: {e}")
            return False
            
    def cleanup(self):
        """Clean up GPIO resources."""
        if not self.initialized:
            return
            
        try:
            self.logger.info("Cleaning up servo controller resources...")
            
            # In a real implementation:
            # for pwm in self.pwm.values():
            #     pwm.stop()
            # GPIO.cleanup()
            
            self.initialized = False
            self.logger.info("Servo controller resources cleaned up")
        except Exception as e:
            self.logger.error(f"Error cleaning up servo controller: {e}")
    
    def set_position(self, pan=None, tilt=None, roll=None):
        """
        Set the position of multiple servos at once.
        
        Args:
            pan (float, optional): Pan position in degrees
            tilt (float, optional): Tilt position in degrees
            roll (float, optional): Roll position in degrees
            
        Returns:
            tuple: Current positions (pan, tilt, roll)
        """
        if pan is not None:
            self.set_servo_position('pan', pan)
        
        if tilt is not None:
            self.set_servo_position('tilt', tilt)
            
        # Roll is not implemented in this basic version
        
        return (
            self.get_position('pan'),
            self.get_position('tilt'),
            90  # Default roll position
        )
    
    def set_servo_position(self, servo_name, degrees):
        """
        Set a servo to a specific position in degrees.
        
        Args:
            servo_name (str): Name of the servo ('pan' or 'tilt')
            degrees (float): Position in degrees (0-180)
            
        Returns:
            bool: True if successful, False otherwise
        """
        if not self.initialized:
            self.logger.error("Servo controller not initialized")
            return False
            
        if servo_name not in self.servo_pins:
            self.logger.error(f"Unknown servo: {servo_name}")
            return False
            
        # Clamp degrees to valid range
        degrees = max(0, min(180, degrees))
        
        try:
            # Calculate duty cycle from degrees
            # For a typical servo, 0 degrees = 0.5ms pulse, 180 degrees = 2.5ms pulse
            # At 50Hz, period is 20ms, so duty cycle is pulse_width / 20ms * 100%
            pulse_width = self.min_pulse_width + (degrees / 180.0) * (self.max_pulse_width - self.min_pulse_width)
            duty_cycle = (pulse_width / (1000 / self.frequency)) * 100
            
            self.logger.debug(f"Setting {servo_name} to {degrees} degrees (duty cycle: {duty_cycle:.2f}%)")
            
            # In a real implementation:
            # self.pwm[servo_name].ChangeDutyCycle(duty_cycle)
            
            # Update current position
            self.current_positions[servo_name] = degrees
            
            # Simulate movement time
            time.sleep(0.1)
            
            return True
        except Exception as e:
            self.logger.error(f"Error setting {servo_name} position: {e}")
            return False
    
    def get_position(self, servo_name):
        """
        Get the current position of a servo.
        
        Args:
            servo_name (str): Name of the servo
            
        Returns:
            float: Position in degrees (0-180) or None if error
        """
        if servo_name not in self.current_positions:
            self.logger.error(f"Unknown servo: {servo_name}")
            return None
            
        return self.current_positions.get(servo_name)
    
    def center(self):
        """
        Center all servos to their middle positions.
        
        Returns:
            tuple: Current positions (pan, tilt, roll)
        """
        self.set_position('pan', 90)
        self.set_position('tilt', 90)
        
        return (
            self.get_position('pan'),
            self.get_position('tilt'),
            90  # Default roll position
        )
    
    def get_status(self):
        """
        Get the current status of all servos.
        
        Returns:
            dict: Servo status information
        """
        return {
            "positions": {
                "pan": self.get_position('pan'),
                "tilt": self.get_position('tilt'),
                "roll": 90  # Default roll position
            },
            "initialized": self.initialized
        }
    
    def shutdown(self):
        """Shut down the servo controller."""
        self.center()  # Center servos before shutdown
        self.cleanup() 


================================================================================
FILE: ./installLibrealsense/README.md
================================================================================

# installLibrealsense
Build and install scripts for Intel's librealsense for the NVIDIA Jetson Nano Developer Kit

Original article on JetsonHacks: https://wp.me/p7ZgI9-34j

The Intel® RealSense™ SDK is here: https://github.com/IntelRealSense/librealsense
The SDK library name is librealsense. This is for version 2 of the library, which supports
the D400 series depth cameras, T265 tracking camera, and the SR300 depth camera.

It is now possible on the NVIDIA Jetsons to do a simple install from a RealSense debian repository
(i.e. apt-get install). Previous versions of this repository require building librealsense from source, and (possibly) rebuilding the Linux kernel.

The current recommendation from Intel is to use UVC for video input on the Jetson family. The
UVC API in librealsense has been rewritten to better support this use case.

<h3>installLibrealsense.sh</h3>
This script will install librealsense from the Intel Librealsense Debian Repository.
<p> 

```
$ ./installLibrealsense.sh
```

<em><b>Note:</b> You do not have to patch modules and kernels.</em>

<h3>buildLibrealsense.sh</h3>
This script will build librealsense from source and install it on the system. <em><b>Note:</b> It is recommended to install from Debian repository as described above. However, if you need to compile from source, you will find this script useful.</em>
<p>

```
$ ./buildLibrealsense.sh [ -v | --version <version> ] [ -j | -jobs <number of jobs> ] [ -n | --no_cuda ]
```

Where:
* `<version>` = Librealsense version. E.g. v2.49.0
* `<number of jobs>` = # of jobs to run concurrently when building. Defaults to 1 if the Jetson has <= 4GB memory
* `<no_cuda>` = Compile without CUDA support. Defaults to CUDA.

The librealsense Github repository has good documentation for supporting more advanced modes for the RealSense sensors. Please see: [installation_jetson.md](https://github.com/IntelRealSense/librealsense/blob/master/doc/installation_jetson.md) The documentation covers different communication interfaces and how to explore different features, some of which may require recompiling kernel modules.
  
<em><b>Note:</b> The build uses libuvc. You will not have to rebuild the kernel or modules in order to use this build.</em>

<h2>Notes</h2>
If you use realsense-ros, make sure that you match the librealsense versions with the realsense-ros version requirement.
  

## Releases
  
### September, 2021
* Release v1.1
* Change release naming for this repository
* Updated keyserver URL
  * Thank you Tomasz @tomek-I and Tommy @Tommyisr !
* Enhanced buildLibrealsense script
* Lookup latest version of librealsense from Github repository
    * Allow override via CLI argument ( -v | -version )
* Allow user to specify number of build jobs ( -j | -jobs )
  * If Jetson has > 4GB use number of cores - 1 ; otherwise 1
* Different parsing of comand line arguments using getopt
* Tested on Jetson Nano, L4T 32.6.1, JetPack 4.6
* installLibrealsense.sh installed v2.49.0
* Thank you Abdul @jazarie2 and Matt @droter for pull requests!

<h4>December, 2019</h4>

* Release vL4T32.3.1
* Jetson Nano
* L4T 32.3.1, JetPack 4.3, Kernel 4.9.
* Also works with L4T 32.2.1 - 32.2.3
* Current  librealsense version v2.31.0
* Fixed Issue: D435i and T265 have issues working together. Upgrading D435i firmware fixes this issue.
* Requires realsense-ros version 2.2.11 
* Now uses libuvc in buildLibrealsense, no need to recompile linux kernel/modules


<h4>November, 2019</h4>

* Release vL4T32.2.3
* Jetson Nano
* L4T 32.2.3, JetPack 4.2.2, Kernel 4.9.
* Also works with L4T 32.2.1
* Currently librealsense version v2.31.0
* Issue: L4T 32.2.3 has issues with using RealSense cameras D435i and T265 simultaneously. Under L4T 32.2.1 appears to work correctly.
* Requires realsense-ros version 2.2.11 
* Now uses libuvc in buildLibrealsense, no need to recompile linux kernel/modules

<h4>October, 2019</h4>

* Release vL4T32.2.1
* Jetson Nano
* L4T 32.2.1, JetPack 4.2.2, Kernel 4.9 
* librealsense version v2.25.0 (matches realsense-ros package)


<h4>July, 2019</h4>

* Release vL4T32.2
* Jetson Nano
* L4T 32.2, Kernel 4.9, JetPack 4.2.1
* Add Python 3 support
* UVC_MAX_STATUS changed in Kernel to 1024, remove Patch 
* Remove URBS UVC patch
* librealsense version v2.24.0

<h4>June, 2019</h4>

* Release vL4T32.1
* Jetson Nano
* L4T 32.1.0, Kernel 4.9-140
* Bump librealsense version to v2.22.0 for compatibility with realsense-ros

<h4>June, 2019</h4>

* Release v0.9
* Jetson Nano
* L4T 32.1.0, Kernel 4.9-140
* Bump librealsense version to v2.22.0 for compatibility with realsense-ros

<h4>May, 2019</h4>

* Release v0.8
* Jetson Nano
* L4T 32.1.0, Kernel 4.9-140
* D435i issue resolved - Make kernel image before modules 


<h4>May 6, 2019</h4>

* Initial Release v0.7
* Jetson Nano
* L4T 32.1.0, Kernel 4.9-140
* D435i issue addressed

<h4>April 30, 2019</h4>
<h4>installLibrealsense.sh</h4>

* Switch CLI argument to build_with_cuda ; Build with CUDA takes a lot more time because CMake needs to be rebuilt. Default is to build without CUDA support

* <em>previous commit</em> Add CLI argument build_no_cuda ; script defaults to build with CUDA. 

* D435i is not recognized by RealSense applications, but shows up in Cheese webcam viewer.


<h4>April 29, 2019</h4>
<h4>installLibrealsense.sh</h4>

Add CUDACXX flag for compilation using CUDA

Add USE_CUDA flag to script (Defaults to YES)

If using only RealSense T265 camera, this is the only installation necessary

<em>If using the T265, you probably don't need CUDA (still needs to be tested); Set USE_CUDA to false. Saves compilation time</em>

During compilation, the script will run out of memory on the Nano
You will need either to:

* Enable swap memory

<b>OR:</b>

* Modify the script to 'make' with only 1 processor

<h4>patchUbuntu.sh</h4>

patchUbuntu will patch all of the needed modules for librealsense, build the modules, and then install the modules. The kernel Image is then built and installed in /boot/Image.

<em><b>Note:</b> If you are building from a USB or some other device than the SD card, you will need to copy the Image file to the /boot directory on the SD card.</em>




================================================================================
FILE: ./requirements.txt
================================================================================

websockets>=10.0
asyncio>=3.4.3
python-socketio>=5.0.0
numpy>=1.19.0
opencv-python>=4.5.0
# Libraries for I2C and hardware interaction
adafruit-blinka>=7.0.0
adafruit-circuitpython-pca9685>=3.4.0
adafruit-circuitpython-servokit>=1.3.0
# GPIO access libraries (newer libraries compatible with Pi 5)
gpiod>=1.5.0
RPi.GPIO>=0.7.0
gpiozero>=2.0
# I2C utilities
smbus2>=0.4.1
# Intel RealSense D455 support
# Note: pyrealsense2 will be installed separately in the start script
# as it might need special handling on Raspberry Pi
# Additional libraries for depth camera processing
open3d>=0.16.0       # For 3D point cloud processing
transforms3d>=0.4.0  # For 3D transformations
scipy>=1.7.0         # Scientific computing (signal processing)
pyusb>=1.2.0         # USB device access (helpful for D455 connectivity) 
# For codebase summarization
python-dotenv>=1.0.0
openai>=1.0.0 


================================================================================
FILE: README.md
================================================================================

# Project Summary
> Last updated: 2025-03-21 08:01:00

# Codebase Summary

## Project Purpose and Main Functionality
The project implements a client-server system primarily designed for a Raspberry Pi equipped with various hardware components such as a RealSense camera, servo motors, and an audio detection system. The main functionality of the system is to capture and process video and audio data, control servo motors based on received commands, and communicate with a server via WebSockets. The system can operate in a real or simulated hardware environment.

## Key Components and Their Interactions
- **WebSocketClient**: Manages the WebSocket connection, handling the sending of telemetry, camera frames, and receiving commands from the server.
- **RealSenseCamera**: Interfaces with an Intel RealSense camera to capture color and depth frames.
- **ServoController**: Manages servo motors for physical movements based on received commands.
- **AudioDetector**: Processes audio signals to detect sound levels and directions.
- **MessageHandler**: Handles sending and receiving messages to/from the server, although detailed implementation is not provided.

These components interact mainly through the `WebSocketClient` class, which orchestrates the data flow between the server and the local hardware components. The client initializes the hardware components, connects to the server, and continuously processes and sends data (like camera frames and telemetry) while receiving and executing commands (like servo movements).

## Technologies and Libraries Used
- **Python 3**: Main programming language.
- **asyncio and websockets**: For asynchronous network programming and WebSocket communication.
- **OpenCV (cv2)**: For image processing tasks.
- **NumPy**: Used for numerical operations, especially in handling image data.
- **logging**: For logging information, warnings, and errors.
- **argparse**: For parsing command-line options.
- **RPi.GPIO, adafruit-blinka**: Libraries for interfacing with the GPIO pins on a Raspberry Pi for controlling hardware like servo motors.

## Notable Implementation Details
- The system can switch between real and simulation modes using a command-line argument, allowing development and testing without actual hardware.
- The client attempts to reconnect to the server with exponential backoff strategy in case of connection losses.
- Telemetry data includes system metrics such as CPU temperature, memory usage, and uptime, which are sent periodically to the server.
- The system is designed to be modular, where each hardware component (camera, servos, audio) is encapsulated in its class with specific responsibilities.

Overall, the system is structured to be robust and modular, facilitating easy maintenance and scalability. The use of asynchronous programming ensures that the system can handle real-time data processing and communication efficiently.

## Auto-generated Summary
This README was automatically generated by a script that concatenates the codebase
and uses OpenAI's API to generate a summary.



================================================================================
FILE: client/client.py
================================================================================

#!/usr/bin/env python3
import asyncio
import websockets
import logging
import json
import time
import base64
import cv2
import numpy as np
import socket
import sys
import argparse
import os
import traceback
from queue import Queue, Empty
import statistics
from typing import Dict, List, Optional, Any
import random

# Import hardware modules
from hardware.camera.realsense_camera import RealSenseCamera
from hardware.servo.controller import ServoController
from hardware.audio.audio_detector import AudioDetector

# Import config and utilities
import config

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("client_log.txt"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Parse command line arguments
parser = argparse.ArgumentParser(description='A2 Pi Client')
parser.add_argument('--server', default=config.SERVER_ADDRESS, help='WebSocket server hostname or IP')
parser.add_argument('--port', type=int, default=config.SERVER_PORT, help='WebSocket server port')
parser.add_argument('--debug', action='store_true', help='Enable debug logging')
parser.add_argument('--simulation', action='store_true', help='Run in simulation mode without hardware')
args = parser.parse_args()

# Set log level
if args.debug:
    logger.setLevel(logging.DEBUG)

# Configuration
SERVER_ADDRESS = args.server
SERVER_PORT = args.port
SIMULATION_MODE = args.simulation or config.SIMULATION_MODE
WS_URL = f"ws://{SERVER_ADDRESS}:{SERVER_PORT}/pi"
RECONNECT_DELAY = 5
MAX_RECONNECT_ATTEMPTS = 10

class WebSocketClient:
    def __init__(self, camera_manager, servo_controller, audio_detector=None):
        """Initialize the WebSocket client"""
        self.camera = camera_manager
        self.servo = servo_controller
        self.audio = audio_detector
        
        self.websocket = None
        self.connected = False
        self.stopping = False
        self.reconnect_attempt = 1
        
        self.frame_count = 0
        self.last_frame_time = 0
        self.last_telemetry_time = 0
        
        # Set up a queue for frames
        self.frame_queue = asyncio.Queue(maxsize=5)
    
    async def connect(self):
        """Connect to the WebSocket server"""
        try:
            # Check server connectivity first
            if not await self.check_server_connectivity():
                logger.warning("Server connectivity check failed, but still trying to connect...")
            
            # Connect with timeout
            logger.info(f"Connecting to {WS_URL}...")
            self.websocket = await asyncio.wait_for(
                websockets.connect(
                    WS_URL,
                    ping_interval=None,  # We'll handle pings manually
                    close_timeout=2,     # Quicker close on errors
                    max_size=20*1024*1024,  # 20MB max message size
                ),
                timeout=10  # 10 second timeout
            )
            
            self.connected = True
            logger.info("Connected to WebSocket server successfully")
            
            # Send hello message
            hello_message = json.dumps({
                "type": "hello",
                "client": "pi",
                "timestamp": time.time(),
                "hostname": socket.gethostname(),
                "simulation_mode": SIMULATION_MODE
            })
            
            logger.info("Sending hello message to server")
            await self.websocket.send(hello_message)
            
            return True
        
        except asyncio.TimeoutError:
            logger.error("Connection timeout")
            self.connected = False
            return False
        except Exception as e:
            logger.error(f"Failed to connect: {e}")
            logger.error(traceback.format_exc())
            self.connected = False
            return False
    
    async def check_server_connectivity(self):
        """Check if the server is reachable"""
        try:
            # Try to resolve hostname
            ip = socket.gethostbyname(SERVER_ADDRESS)
            logger.info(f"Resolved {SERVER_ADDRESS} to {ip}")
            
            # Try to connect to the port
            s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            s.settimeout(2)
            s.connect((ip, SERVER_PORT))
            s.close()
            logger.info(f"Successfully connected to {ip}:{SERVER_PORT}")
            return True
        except Exception as e:
            logger.error(f"Connectivity check failed: {e}")
            return False
    
    async def process_frames(self):
        """Process and send frames from the camera"""
        while self.connected and not self.stopping:
            try:
                # Get a frame from the camera
                frame = self.camera.get_color_frame()
                
                if frame is None:
                    logger.warning("Failed to get frame from camera")
                    await asyncio.sleep(0.1)
                    continue
                
                # Increment frame count
                self.frame_count += 1
                
                # Only process every N frames to reduce load
                if self.frame_count % config.SEND_EVERY_N_FRAMES == 0:
                    # Calculate FPS
                    now = time.time()
                    if self.last_frame_time > 0:
                        fps = 1.0 / (now - self.last_frame_time)
                    else:
                        fps = 30.0
                    self.last_frame_time = now
                    
                    # Encode frame to JPEG
                    encode_params = [cv2.IMWRITE_JPEG_QUALITY, config.JPEG_QUALITY]
                    ret, jpeg = cv2.imencode('.jpg', frame, encode_params)
                    
                    if not ret:
                        logger.error("Failed to encode frame")
                        continue
                    
                    # Convert to base64 for sending via WebSocket
                    frame_data = base64.b64encode(jpeg.tobytes()).decode('utf-8')
                    
                    # Get additional camera data if available
                    camera_info = {}
                    depth_data = None
                    
                    if hasattr(self.camera, 'get_camera_info'):
                        camera_info = self.camera.get_camera_info()
                    
                    if hasattr(self.camera, 'get_depth_frame'):
                        depth_frame = self.camera.get_depth_frame()
                        if depth_frame is not None:
                            # Encode depth frame as base64
                            depth_png = cv2.imencode('.png', depth_frame)[1].tobytes()
                            depth_data = base64.b64encode(depth_png).decode('utf-8')
                    
                    # Create frame message
                    frame_message = {
                        "type": "frame",
                        "frame_id": self.frame_count,
                        "timestamp": time.time(),
                        "image": frame_data,
                        "depth_data": depth_data,
                        "camera_info": {
                            "model": camera_info.get("name", "D455"),
                            "serial": camera_info.get("serial", "unknown"),
                            "resolution": [self.camera.width, self.camera.height]
                        },
                        "depth_scale": 0.001,  # Meters per unit
                        "fps": fps
                    }
                    
                    # Send the frame
                    await self.websocket.send(json.dumps(frame_message))
                    logger.debug(f"Sent frame {self.frame_count}")
                
                # Sleep briefly to avoid overwhelming the system
                await asyncio.sleep(0.01)
            
            except websockets.exceptions.ConnectionClosed:
                logger.warning("Connection closed while sending frame")
                self.connected = False
                break
            except Exception as e:
                logger.error(f"Error in frame processing: {e}")
                logger.error(traceback.format_exc())
                await asyncio.sleep(0.5)
    
    async def send_telemetry(self):
        """Send periodic telemetry data"""
        while self.connected and not self.stopping:
            try:
                # Only send telemetry every few seconds
                now = time.time()
                if now - self.last_telemetry_time < config.TELEMETRY_INTERVAL:
                    await asyncio.sleep(0.1)
                    continue
                
                self.last_telemetry_time = now
                
                # Collect telemetry data
                telemetry = {
                    "type": "telemetry",
                    "timestamp": now,
                    "system": {
                        "hostname": socket.gethostname(),
                        "uptime": self.get_uptime(),
                        "temperature": self.get_cpu_temperature(),
                        "memory": self.get_memory_usage()
                    },
                    "servo": self.servo.get_status(),
                }
                
                # Add audio data if available
                if self.audio:
                    audio_levels = self.audio.read_all_microphones()
                    telemetry["audio"] = {
                        "levels": audio_levels,
                        "direction": self.audio.detect_direction()
                    }
                
                # Send telemetry
                await self.websocket.send(json.dumps(telemetry))
                logger.debug("Sent telemetry data")
            
            except websockets.exceptions.ConnectionClosed:
                logger.warning("Connection closed while sending telemetry")
                self.connected = False
                break
            except Exception as e:
                logger.error(f"Error sending telemetry: {e}")
                logger.error(traceback.format_exc())
                await asyncio.sleep(0.5)
    
    async def receive_data(self):
        """Receive and handle incoming messages from the server"""
        while self.connected and not self.stopping:
            try:
                # Receive message
                message = await self.websocket.recv()
                
                # Parse JSON
                try:
                    data = json.loads(message)
                    message_type = data.get("type", "unknown")
                    
                    logger.debug(f"Received message of type: {message_type}")
                    
                    if message_type == "control":
                        # Handle control message
                        action = data.get("action")
                        
                        if action == "move_servos":
                            # Update servo positions
                            params = data.get("params", {})
                            
                            if "pan" in params or "tilt" in params or "roll" in params:
                                # Update servo positions
                                pan = params.get("pan")
                                tilt = params.get("tilt")
                                roll = params.get("roll")
                                
                                # Move servos
                                result = self.servo.set_position(pan=pan, tilt=tilt, roll=roll)
                                
                                # Send confirmation
                                response = {
                                    "type": "control_response",
                                    "action": "move_servos",
                                    "success": True,
                                    "position": {
                                        "pan": result[0],
                                        "tilt": result[1],
                                        "roll": result[2]
                                    },
                                    "timestamp": time.time()
                                }
                                
                                await self.websocket.send(json.dumps(response))
                        
                        elif action == "center_servos":
                            # Center all servos
                            result = self.servo.center()
                            
                            # Send confirmation
                            response = {
                                "type": "control_response",
                                "action": "center_servos",
                                "success": True,
                                "position": {
                                    "pan": result[0],
                                    "tilt": result[1],
                                    "roll": result[2]
                                },
                                "timestamp": time.time()
                            }
                            
                            await self.websocket.send(json.dumps(response))
                    
                    elif message_type == "ping":
                        # Respond with pong
                        await self.websocket.send(json.dumps({
                            "type": "pong",
                            "timestamp": time.time()
                        }))
                    
                    elif message_type == "detection_result":
                        # Handle detection results
                        frame_id = data.get("frame_id")
                        detections = data.get("detections", [])
                        
                        if detections:
                            # Use detections for tracking or other purposes
                            logger.debug(f"Received {len(detections)} detections for frame {frame_id}")
                    
                    elif message_type == "welcome":
                        # Server acknowledged our connection
                        logger.info("Server acknowledged connection with welcome message")
                
                except json.JSONDecodeError:
                    logger.error("Received invalid JSON")
            
            except websockets.exceptions.ConnectionClosed:
                logger.warning("Connection closed during receive")
                self.connected = False
                break
            except Exception as e:
                logger.error(f"Error receiving data: {e}")
                logger.error(traceback.format_exc())
                await asyncio.sleep(0.5)
    
    async def maintain_connection(self):
        """Send periodic heartbeats to keep the connection alive"""
        while self.connected and not self.stopping:
            try:
                # Send a ping every 30 seconds
                await asyncio.sleep(30)
                
                if self.connected:
                    await self.websocket.send(json.dumps({
                        "type": "ping",
                        "timestamp": time.time()
                    }))
                    logger.debug("Sent ping")
            
            except websockets.exceptions.ConnectionClosed:
                logger.warning("Connection closed during heartbeat")
                self.connected = False
                break
            except Exception as e:
                logger.error(f"Error sending heartbeat: {e}")
                await asyncio.sleep(0.5)
    
    async def run_client(self):
        """Main method to run the WebSocket client"""
        logger.info("Starting WebSocket client...")
        
        while not self.stopping:
            try:
                # Connect to server
                connected = await self.connect()
                
                if connected:
                    # Start tasks
                    tasks = [
                        asyncio.create_task(self.process_frames()),
                        asyncio.create_task(self.send_telemetry()),
                        asyncio.create_task(self.receive_data()),
                        asyncio.create_task(self.maintain_connection())
                    ]
                    
                    # Wait for any task to complete (which typically means an error occurred)
                    _, pending = await asyncio.wait(
                        tasks,
                        return_when=asyncio.FIRST_COMPLETED
                    )
                    
                    # Cancel pending tasks
                    for task in pending:
                        task.cancel()
                    
                    # If we get here, the connection was lost
                    self.connected = False
                
                # Try to reconnect if not stopping
                if not self.stopping:
                    self.reconnect_attempt += 1
                    
                    if self.reconnect_attempt > MAX_RECONNECT_ATTEMPTS:
                        logger.error(f"Exceeded maximum reconnect attempts ({MAX_RECONNECT_ATTEMPTS}), giving up")
                        return
                    
                    # Wait with exponential backoff
                    delay = min(RECONNECT_DELAY * (1.5 ** (self.reconnect_attempt - 1)), 60)
                    jitter = random.uniform(0, 2)
                    total_delay = delay + jitter
                    
                    logger.info(f"Reconnecting in {total_delay:.1f} seconds (attempt {self.reconnect_attempt}/{MAX_RECONNECT_ATTEMPTS})...")
                    await asyncio.sleep(total_delay)
            
            except Exception as e:
                logger.error(f"Error in client main loop: {e}")
                logger.error(traceback.format_exc())
                await asyncio.sleep(5)
    
    async def stop(self):
        """Stop the client gracefully"""
        logger.info("Stopping client...")
        self.stopping = True
        
        # Close WebSocket connection
        if self.websocket:
            await self.websocket.close()
    
    def get_uptime(self):
        """Get system uptime in seconds"""
        try:
            with open('/proc/uptime', 'r') as f:
                uptime_seconds = float(f.readline().split()[0])
            return uptime_seconds
        except:
            return 0
    
    def get_cpu_temperature(self):
        """Get CPU temperature in Celsius"""
        try:
            temp = 0
            if os.path.exists('/sys/class/thermal/thermal_zone0/temp'):
                with open('/sys/class/thermal/thermal_zone0/temp') as f:
                    temp = float(f.read()) / 1000.0
            return temp
        except:
            return 0
    
    def get_memory_usage(self):
        """Get memory usage statistics"""
        try:
            with open('/proc/meminfo', 'r') as f:
                lines = f.readlines()
            
            mem_info = {}
            for line in lines:
                if ":" in line:
                    key, value = line.split(':')
                    value = value.strip()
                    if value.endswith('kB'):
                        value = int(value[:-2]) * 1024
                    mem_info[key.strip()] = value
            
            total = int(mem_info.get('MemTotal', 0))
            free = int(mem_info.get('MemFree', 0))
            available = int(mem_info.get('MemAvailable', 0))
            
            if total > 0:
                used_percent = 100 * (total - available) / total
            else:
                used_percent = 0
            
            return {
                "total": total,
                "free": free,
                "available": available,
                "used_percent": used_percent
            }
        except:
            return {
                "total": 0,
                "free": 0,
                "available": 0,
                "used_percent": 0
            }

def init_system():
    """Initialize all system components"""
    global SIMULATION_MODE
    logger.info("Initializing system components...")
    
    # Initialize camera
    logger.info("Initializing camera...")
    camera_manager = RealSenseCamera(
        width=config.FRAME_WIDTH,
        height=config.FRAME_HEIGHT,
        fps=config.FRAME_RATE,
        simulation_mode=SIMULATION_MODE
    )
    success = camera_manager.initialize()
    
    if success:
        logger.info("Camera initialized successfully")
        camera_manager.start_streaming()
    else:
        logger.error("Failed to initialize camera")
        if not SIMULATION_MODE:
            logger.warning("Falling back to simulation mode")
            SIMULATION_MODE = True
            camera_manager = RealSenseCamera(
                width=config.FRAME_WIDTH,
                height=config.FRAME_HEIGHT,
                fps=config.FRAME_RATE,
                simulation_mode=True
            )
            camera_manager.initialize()
            camera_manager.start_streaming()
    
    # Initialize servo controller
    logger.info("Initializing servo controller...")
    try:
        servo_config = {
            'servo_pins': {
                'pan': config.PAN_CHANNEL,
                'tilt': config.TILT_CHANNEL
            },
            'min_pulse_width': 0.5,
            'max_pulse_width': 2.5,
            'frequency': 50
        }
        servo_controller = ServoController(config=servo_config)
        servo_controller.initialize()
        logger.info("Servo controller initialized")
    except Exception as e:
        logger.error(f"Failed to initialize servo controller: {e}")
        logger.error(traceback.format_exc())
        logger.warning("Using simulated servo controller")
        servo_controller = ServoController()
    
    # Initialize audio detector
    logger.info("Initializing audio detector...")
    try:
        audio_detector = AudioDetector(simulation_mode=SIMULATION_MODE)
        audio_detector.initialize()
        logger.info("Audio detector initialized")
    except Exception as e:
        logger.error(f"Failed to initialize audio detector: {e}")
        logger.warning("Audio detection will not be available")
        audio_detector = None
    
    # Initialize WebSocket client
    logger.info("Initializing WebSocket client...")
    websocket_client = WebSocketClient(
        camera_manager=camera_manager,
        servo_controller=servo_controller,
        audio_detector=audio_detector
    )
    
    return camera_manager, servo_controller, audio_detector, websocket_client

def main():
    """Main entry point"""
    # Display startup information
    logger.info(f"A2 Pi Client v{config.VERSION}")
    logger.info(f"Server: {SERVER_ADDRESS}:{SERVER_PORT}")
    logger.info(f"Simulation mode: {SIMULATION_MODE}")
    
    # Initialize system components
    camera_manager, servo_controller, audio_detector, websocket_client = init_system()
    
    try:
        # Create and get event loop
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        # Run the client
        loop.run_until_complete(websocket_client.run_client())
    except KeyboardInterrupt:
        logger.info("Client terminated by user")
    except Exception as e:
        logger.error(f"Fatal error: {e}")
        logger.error(traceback.format_exc())
    finally:
        # Shutdown resources
        logger.info("Shutting down...")
        
        # Stop WebSocket client
        try:
            loop.run_until_complete(websocket_client.stop())
        except:
            pass
        
        # Stop camera
        try:
            camera_manager.stop_streaming()
        except:
            pass
        
        # Reset servos to center position
        try:
            servo_controller.center()
            servo_controller.shutdown()
        except:
            pass
        
        logger.info("Shutdown complete")

if __name__ == "__main__":
    main()


================================================================================
FILE: client/message_handler.py
================================================================================

#!/usr/bin/env python3
"""
Message processing logic for the Pi client.
"""

import json
import logging

class MessageHandler:
    def __init__(self, config):
        """Initialize the message handler with configuration."""
        self.config = config
        self.logger = logging.getLogger(__name__)
        
    def send(self, message):
        """
        Send a message to the server.
        
        Args:
            message (dict): The message to send
            
        Returns:
            bool: True if successful, False otherwise
        """
        try:
            # Serialize the message
            serialized = json.dumps(message)
            
            # Send the message (implement actual sending mechanism)
            self.logger.info(f"Sending message: {serialized}")
            
            # For now just log it
            return True
        except Exception as e:
            self.logger.error(f"Failed to send message: {e}")
            return False
    
    def receive(self):
        """
        Receive a message from the server.
        
        Returns:
            dict: The received message or None if no message available
        """
        try:
            # Implement actual message receiving here
            self.logger.debug("Checking for messages")
            
            # Mock received message for now
            return None
        except Exception as e:
            self.logger.error(f"Failed to receive message: {e}")
            return None
    
    def process(self, message):
        """
        Process a received message.
        
        Args:
            message (dict): The message to process
            
        Returns:
            dict: Response message if any
        """
        if not message:
            return None
            
        try:
            # Parse message type and respond accordingly
            msg_type = message.get('type', '')
            
            if msg_type == 'command':
                return self._handle_command(message)
            elif msg_type == 'query':
                return self._handle_query(message)
            else:
                self.logger.warning(f"Unknown message type: {msg_type}")
                return {'status': 'error', 'error': 'Unknown message type'}
                
        except Exception as e:
            self.logger.error(f"Error processing message: {e}")
            return {'status': 'error', 'error': str(e)}
    
    def _handle_command(self, message):
        """Handle command messages."""
        command = message.get('command', '')
        self.logger.info(f"Handling command: {command}")
        
        # Implement command handling logic
        return {'status': 'success', 'command': command}
    
    def _handle_query(self, message):
        """Handle query messages."""
        query = message.get('query', '')
        self.logger.info(f"Handling query: {query}")
        
        # Implement query handling logic
        return {'status': 'success', 'query': query, 'result': None} 


================================================================================
FILE: config.py
================================================================================

"""
Configuration file for the A2 Pi Client
"""

import os
import logging

# Version
VERSION = "1.0.0"

# System settings
DEBUG = os.environ.get('DEBUG', 'False').lower() == 'true'
LOG_LEVEL = logging.DEBUG if DEBUG else logging.INFO
SIMULATION_MODE = os.environ.get('SIMULATION_MODE', 'False').lower() == 'true'

# Server settings
SERVER_ADDRESS = os.environ.get('SERVER_ADDRESS', '192.168.50.86')  # WebSocket server address
SERVER_PORT = int(os.environ.get('SERVER_PORT', '5000'))

# Camera settings
FRAME_WIDTH = int(os.environ.get('FRAME_WIDTH', '640'))
FRAME_HEIGHT = int(os.environ.get('FRAME_HEIGHT', '480'))
FRAME_RATE = int(os.environ.get('FRAME_RATE', '30'))
JPEG_QUALITY = int(os.environ.get('JPEG_QUALITY', '75'))
SEND_EVERY_N_FRAMES = int(os.environ.get('SEND_EVERY_N_FRAMES', '2'))  # Send every 2nd frame

# Telemetry settings
TELEMETRY_INTERVAL = float(os.environ.get('TELEMETRY_INTERVAL', '1.0'))  # Send telemetry every 1 second

# Servo settings
PAN_CHANNEL = 0
TILT_CHANNEL = 1
ROLL_CHANNEL = 2
PAN_LIMITS = (-80, 80)
TILT_LIMITS = (-45, 45)
ROLL_LIMITS = (-30, 30)


================================================================================
FILE: requirements.txt
================================================================================

websockets>=10.0
asyncio>=3.4.3
python-socketio>=5.0.0
numpy>=1.19.0
opencv-python>=4.5.0
# Libraries for I2C and hardware interaction
adafruit-blinka>=7.0.0
adafruit-circuitpython-pca9685>=3.4.0
adafruit-circuitpython-servokit>=1.3.0
# GPIO access libraries (newer libraries compatible with Pi 5)
gpiod>=1.5.0
RPi.GPIO>=0.7.0
gpiozero>=2.0
# I2C utilities
smbus2>=0.4.1
# Intel RealSense D455 support
# Note: pyrealsense2 will be installed separately in the start script
# as it might need special handling on Raspberry Pi
# Additional libraries for depth camera processing
open3d>=0.16.0       # For 3D point cloud processing
transforms3d>=0.4.0  # For 3D transformations
scipy>=1.7.0         # Scientific computing (signal processing)
pyusb>=1.2.0         # USB device access (helpful for D455 connectivity) 
# For codebase summarization
python-dotenv>=1.0.0
openai>=1.0.0 

================================================================================
UPDATED README.md
================================================================================

# Project Summary
> Last updated: 2025-03-21 08:04:30

# Project Summary

## Purpose and Main Functionality
The project is designed to create a client-server system for a Raspberry Pi equipped with various hardware components such as a RealSense camera, servo motors, and an audio detection system. The primary functionalities include:
- Capturing and processing video and audio data.
- Controlling servo motors based on commands received from a server.
- Communicating with a server through WebSockets.
- Operating in both real and simulated hardware environments for development and testing purposes.

## Key Components and Interactions
- **WebSocketClient**: Manages WebSocket connections, sends telemetry and camera frames, and receives commands from the server.
- **RealSenseCamera**: Captures color and depth frames using an Intel RealSense camera.
- **ServoController**: Controls servo motors to adjust physical movements based on server commands.
- **AudioDetector**: Analyzes audio signals to determine sound levels and directions.
- **MessageHandler**: Responsible for sending and receiving messages to/from the server (implementation details are not fully provided in the provided code).

These components primarily interact through the `WebSocketClient`, which orchestrates the flow of data and commands between the server and local hardware components.

## Technologies and Libraries
- **Python 3**: The main programming language used.
- **asyncio and websockets**: For asynchronous programming and WebSocket communication.
- **OpenCV (cv2)**: Handles image processing tasks.
- **NumPy**: Utilized for numerical operations, especially in handling image data.
- **RPi.GPIO, adafruit-blinka**: Interface with the GPIO pins on a Raspberry Pi for hardware control.
- **Logging**: For logging information, warnings, and errors.
- **Argparse**: To parse command-line options.

## Notable Implementation Details
- The system supports a simulation mode, allowing development and testing without actual hardware.
- Implements an exponential backoff strategy for reconnecting to the server in case of connection losses.
- Telemetry data includes system metrics like CPU temperature, memory usage, and uptime, sent periodically to the server.
- Designed to be modular, with each hardware component encapsulated in its class, enhancing maintainability and scalability.
- Asynchronous programming is utilized to efficiently handle real-time data processing and communication.

Overall, the system is structured to be robust and modular, facilitating easy maintenance and scalability. The use of asynchronous programming ensures efficient real-time data processing and communication.

## Auto-generated Summary
This README was automatically generated by a script that concatenates the codebase
and uses OpenAI's API to generate a summary.
